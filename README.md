ğŸ“˜ Facial Expression Training (PyTorch + timm)

EN: Training pipeline for Facial Expression Recognition (FER) using PyTorch + timm (ResNet-18 / MobileNetV3).
VI: Pipeline huáº¥n luyá»‡n nháº­n diá»‡n cáº£m xÃºc khuÃ´n máº·t vá»›i PyTorch + timm (ResNet-18 / MobileNetV3).

ğŸ“‚ Project layout / Cáº¥u trÃºc thÆ° má»¥c
fer_project/
â”œâ”€ fer_train_singlefile_speed_patched.py       # main training script
â”œâ”€ requirements.txt
â”œâ”€ checkpoints/                                # saved epoch_xxx.pt, class_names.json
â”œâ”€ weights/                                    # best .pth saved here
â””â”€ dataset/
   â”œâ”€ train/
   â”‚   â”œâ”€â”€ angry/
   â”‚   â”œâ”€â”€ disgust/
   â”‚   â”œâ”€â”€ fear/
   â”‚   â”œâ”€â”€ happy/
   â”‚   â”œâ”€â”€ sad/
   â”‚   â”œâ”€â”€ surprise/
   â”‚   â””â”€â”€ neutral/
   â””â”€ val/
       â”œâ”€â”€ angry/
       â”œâ”€â”€ disgust/
       â”œâ”€â”€ fear/
       â”œâ”€â”€ happy/
       â”œâ”€â”€ sad/
       â”œâ”€â”€ surprise/
       â””â”€â”€ neutral/


EN: Folder names under train/ and val/ must match.
VI: TÃªn thÆ° má»¥c trong train/ vÃ  val/ pháº£i trÃ¹ng nhau.

âš™ï¸ Setup / CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
# create virtual env / táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv venv

# activate
# Windows:
venv\Scripts\activate
# macOS / Linux:
source venv/bin/activate

# install dependencies / cÃ i thÆ° viá»‡n
pip install -r requirements.txt

ğŸš€ Run training / Cháº¡y huáº¥n luyá»‡n
Basic command (default ResNet-18) / Lá»‡nh cÆ¡ báº£n
python fer_train_singlefile_speed_patched.py \
  --train_dir ./dataset/train \
  --val_dir ./dataset/val \
  --epochs 40 \
  --batch_size 128

Full features (Mixup + CutMix + resume)
python fer_train_singlefile_speed_patched.py \
  --train_dir ./dataset/train \
  --val_dir ./dataset/val \
  --epochs 40 \
  --batch_size 128 \
  --lr 1e-3 \
  --use_mixup \
  --use_cutmix \
  --resume


TIP / Gá»£i Ã½:

Use --model mobilenet_v3_small for lightweight model.

DÃ¹ng --model mobilenet_v3_small náº¿u cáº§n model nháº¹.

ğŸ”§ Important arguments / Tham sá»‘ quan trá»ng
--train_dir          path to training dataset
--val_dir            path to validation dataset
--model              resnet18 | mobilenet_v3_small
--epochs             number of epochs (default 40)
--batch_size         batch size (default 128)
--lr                 learning rate (default 1e-3)
--lr_backbone        backbone lr (default 1e-4)
--use_mixup          enable Mixup
--use_cutmix         enable CutMix
--autosave_minutes   auto-save checkpoint every N minutes
--resume             resume training from checkpoint


EN:
Optimizer = AdamW
Scheduler = CosineAnnealingLR
Loss = CrossEntropy + label smoothing

VI:
Optimizer = AdamW
Scheduler = CosineAnnealingLR
Loss = CrossEntropy + label smoothing

ğŸ“ˆ Outputs / Káº¿t quáº£ huáº¥n luyá»‡n

Sau khi train xong:

checkpoints/
  â”œâ”€ epoch_001.pt
  â”œâ”€ epoch_002.pt
  â”œâ”€ ...
  â””â”€ class_names.json

weights/
  â””â”€ resnet18_best_from_scratch.pth     # best validation accuracy


EN: This .pth file is used later in your macOS / Windows / iOS apps.
VI: File .pth nÃ y dÃ¹ng cho app desktop / macOS / iOS sau nÃ y.

ğŸ§ª Quick inference example / VÃ­ dá»¥ suy luáº­n nhanh
import cv2, torch
import numpy as np
from torchvision import transforms
from fer_model import build_model

IMG_SIZE = 224
mean = [0.485, 0.456, 0.406]
std  = [0.229, 0.224, 0.225]

tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])

img = cv2.imread("face.jpg")
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = tf(img).unsqueeze(0)

model = build_model("resnet18", 7)
state = torch.load("weights/resnet18_best_from_scratch.pth", map_location="cpu")
model.load_state_dict(state)
model.eval()

with torch.no_grad():
    logits = model(img)
    k = logits.argmax(1).item()
    print("Predicted class index:", k)

ğŸ“¦ Applications / á»¨ng dá»¥ng

EN:
This trained model can be used for:

macOS desktop emotion recognition app (PySide6)

Windows PyInstaller standalone app

iOS real-time FER app (SwiftUI + CoreML)

StyleGAN augmentation

VI:
Model huáº¥n luyá»‡n dÃ¹ng Ä‘Æ°á»£c cho:

App nháº­n diá»‡n cáº£m xÃºc macOS (PySide6)

App Windows (PyInstaller)

App iOS real-time báº±ng CoreML

TÄƒng cÆ°á»ng dá»¯ liá»‡u báº±ng StyleGAN
